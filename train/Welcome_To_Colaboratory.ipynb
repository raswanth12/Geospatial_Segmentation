{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwFnJsE6vjf8"
      },
      "outputs": [],
      "source": [
        "! pip install rasterio\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import rasterio\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iv3rA1iJvUgA"
      },
      "outputs": [],
      "source": [
        "# Define the DiceLoss class\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        intersection = torch.sum(inputs * targets)\n",
        "        cardinality = torch.sum(inputs) + torch.sum(targets)\n",
        "        dice = (2. * intersection + self.smooth) / (cardinality + self.smooth)\n",
        "        return 1 - dice\n",
        "\n",
        "        # Instantiate the DiceLoss\n",
        "dice_loss = DiceLoss()\n",
        "\n",
        "# Instantiate the CrossEntropyLoss\n",
        "cross_entropy_loss = nn.CrossEntropyLoss()\n",
        "# Combining the two losses\n",
        "def combined_loss(outputs, targets):\n",
        "    ce_loss = cross_entropy_loss(outputs, targets)\n",
        "    dice_loss_val = dice_loss(outputs, targets)\n",
        "    return ce_loss + dice_loss_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W4WRYCjvUc0"
      },
      "outputs": [],
      "source": [
        "def double_conv_3d(in_channels, out_channels):\n",
        "    conv = nn.Sequential(\n",
        "        nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "    return conv\n",
        "\n",
        "def crop_img_3d(tensor, target_sensor):\n",
        "    target_size = target_sensor.size()[2]\n",
        "    tensor_size = tensor.size()[2]\n",
        "    delta = tensor_size - target_size\n",
        "    delta = delta // 2\n",
        "    return tensor[:, :, delta:tensor_size-delta, delta:tensor_size-delta, delta:tensor_size-delta]\n",
        "\n",
        "class UNet3D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet3D, self).__init__()\n",
        "\n",
        "        self.max_pool_2x2x2 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        self.down_conv_1 = double_conv_3d(1, 64)\n",
        "        self.down_conv_2 = double_conv_3d(64, 128)\n",
        "        self.down_conv_3 = double_conv_3d(128, 256)\n",
        "        self.down_conv_4 = double_conv_3d(256, 512)\n",
        "        self.down_conv_5 = double_conv_3d(512, 1024)\n",
        "\n",
        "        self.up_trans_1 = nn.ConvTranspose3d(in_channels=1024, out_channels=512,\n",
        "                                             kernel_size=2, stride=2)\n",
        "        self.up_conv_1 = double_conv_3d(1024, 512)\n",
        "\n",
        "        self.up_trans_2 = nn.ConvTranspose3d(in_channels=512, out_channels=256,\n",
        "                                             kernel_size=2, stride=2)\n",
        "        self.up_conv_2 = double_conv_3d(512, 256)\n",
        "\n",
        "        self.up_trans_3 = nn.ConvTranspose3d(in_channels=256, out_channels=128,\n",
        "                                             kernel_size=2, stride=2)\n",
        "        self.up_conv_3 = double_conv_3d(256, 128)\n",
        "\n",
        "        self.up_trans_4 = nn.ConvTranspose3d(in_channels=128, out_channels=64,\n",
        "                                             kernel_size=2, stride=2)\n",
        "        self.up_conv_4 = double_conv_3d(128, 64)\n",
        "\n",
        "        self.out = nn.Conv3d(in_channels=64, out_channels=2, kernel_size=1)\n",
        "\n",
        "    def forward(self, image):\n",
        "        # Encoder\n",
        "        x1 = self.down_conv_1(image)\n",
        "        x2 = self.max_pool_2x2x2(x1)\n",
        "        x3 = self.down_conv_2(x2)\n",
        "        x4 = self.max_pool_2x2x2(x3)\n",
        "        x5 = self.down_conv_3(x4)\n",
        "        x6 = self.max_pool_2x2x2(x5)\n",
        "        x7 = self.down_conv_4(x6)\n",
        "        x8 = self.max_pool_2x2x2(x7)\n",
        "        x9 = self.down_conv_5(x8)\n",
        "        print(\"Encoded feature size:\", x9.size())\n",
        "\n",
        "        # Decoder\n",
        "        x = self.up_trans_1(x9)\n",
        "        y = crop_img_3d(x7, x)\n",
        "        x = self.up_conv_1(torch.cat([x, y], 1))\n",
        "\n",
        "        x = self.up_trans_2(x)\n",
        "        y = crop_img_3d(x5, x)\n",
        "        x = self.up_conv_2(torch.cat([x, y], 1))\n",
        "\n",
        "        x = self.up_trans_3(x)\n",
        "        y = crop_img_3d(x3, x)\n",
        "        x = self.up_conv_3(torch.cat([x, y], 1))\n",
        "\n",
        "        x = self.up_trans_4(x)\n",
        "        y = crop_img_3d(x1, x)\n",
        "        x = self.up_conv_4(torch.cat([x, y], 1))\n",
        "\n",
        "        x = self.out(x)\n",
        "        print(x.size())\n",
        "        return x\n",
        "\n",
        "# Example usage:\n",
        "depth = 23\n",
        "height = 846\n",
        "width = 1262\n",
        "model = UNet3D()\n",
        "image = torch.rand(1, 1, depth, height, width)\n",
        "output = model(image)\n",
        "print(output.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWHIWyitvUZ3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class TiffDataset(Dataset):\n",
        "    def __init__(self, tif_path):\n",
        "        self.tif_path = tif_path\n",
        "        # Open the TIFF file\n",
        "        with rasterio.open(tif_path) as src:\n",
        "            # Read the image bands\n",
        "            self.image = src.read()  # Shape: (bands, height, width)\n",
        "            # Normalize the image bands\n",
        "            self.image = self.image.astype(np.float32) / 255.0  # Assuming pixel values are in [0, 255]\n",
        "            # Transpose the image to (height, width, bands) for PyTorch\n",
        "            self.image = np.transpose(self.image, (1, 2, 0))\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1  # Since we have only one image\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.image.transpose((2, 0, 1))).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Define your TIFF file path\n",
        "tif_path = \"/content/drive/MyDrive/Sentinal.tif\"\n",
        "# Create dataset and data loader\n",
        "dataset = TiffDataset(tif_path)\n",
        "data_loader = DataLoader(dataset, batch_size=1, shuffle=False)  # Assuming batch size of 1\n",
        "\n",
        "# Iterate over the data loader\n",
        "for images in data_loader:\n",
        "    # images will contain the input image tensor\n",
        "    print(images.shape)  # Shape: (batch_size, channels, height, width)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNet().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    total_loss = 0.0\n",
        "\n",
        "    # Iterate over the data loader\n",
        "    for images in data_loader:\n",
        "        # Transfer data to GPU if available\n",
        "        images = images.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = combined_loss(outputs, targets)  # Assuming targets are available\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Optimize\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate the total loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Print the average loss for this epoch\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(data_loader)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTRGxpaZvUXL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTfkbsFbvUUX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-Z6XHt3vURq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1LxlXR0vUPK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otTIxE9GvUOq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xT9wVPsFvUGz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7p-0dH3vUEU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzqTwew_vUDu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
